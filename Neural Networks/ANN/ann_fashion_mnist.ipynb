{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Arm2Q-y_zt0k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "5Xss4r4l4iF6",
        "outputId": "219f8531-d105-4dd8-aaa7-000d203e8255"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cc4e27e5-2428-44db-96a1-9816c76b9a25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "      <td>228</td>\n",
              "      <td>228</td>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>81</td>\n",
              "      <td>133</td>\n",
              "      <td>184</td>\n",
              "      <td>201</td>\n",
              "      <td>190</td>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>205</td>\n",
              "      <td>196</td>\n",
              "      <td>213</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>117</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>117</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>144</td>\n",
              "      <td>152</td>\n",
              "      <td>...</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>161</td>\n",
              "      <td>148</td>\n",
              "      <td>159</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>148</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>148</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>145</td>\n",
              "      <td>142</td>\n",
              "      <td>142</td>\n",
              "      <td>142</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>114</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>69</td>\n",
              "      <td>88</td>\n",
              "      <td>86</td>\n",
              "      <td>94</td>\n",
              "      <td>106</td>\n",
              "      <td>114</td>\n",
              "      <td>118</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>145</td>\n",
              "      <td>114</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>165</td>\n",
              "      <td>153</td>\n",
              "      <td>155</td>\n",
              "      <td>134</td>\n",
              "      <td>143</td>\n",
              "      <td>172</td>\n",
              "      <td>215</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>190</td>\n",
              "      <td>178</td>\n",
              "      <td>194</td>\n",
              "      <td>209</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>205</td>\n",
              "      <td>211</td>\n",
              "      <td>215</td>\n",
              "      <td>213</td>\n",
              "      <td>217</td>\n",
              "      <td>225</td>\n",
              "      <td>228</td>\n",
              "      <td>213</td>\n",
              "      <td>203</td>\n",
              "      <td>174</td>\n",
              "      <td>151</td>\n",
              "      <td>188</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4e27e5-2428-44db-96a1-9816c76b9a25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc4e27e5-2428-44db-96a1-9816c76b9a25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc4e27e5-2428-44db-96a1-9816c76b9a25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7c924751-7363-48e4-9d19-b4ae7af84717\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c924751-7363-48e4-9d19-b4ae7af84717')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7c924751-7363-48e4-9d19-b4ae7af84717 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      9       0       0       0  ...       213       165         0         0\n",
              "1      7       0       0       0  ...         0         0         0         0\n",
              "2      0       0       0       0  ...         0         0         0         0\n",
              "3      8       0       0       0  ...         0         0         0         0\n",
              "4      8       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read the data\n",
        "df = pd.read_csv('/content/fmnist_small.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "0KvoG3Q04iIh",
        "outputId": "1cfd84a2-8d43-434a-beb3-caea5bdf2f64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# label is the output having 10 diff classes\n",
        "\n",
        "# plotting some of them\n",
        "\n",
        "fig,axes = plt.subplots(2,4,figsize=(10,6))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "  ax.imshow(df.iloc[i,1:].values.reshape(28,28),cmap='gray')\n",
        "  ax.set_title(df.iloc[i,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CNqyiUNC4iLB"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "x = df.iloc[:,1:]\n",
        "y = df.iloc[:,0]\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h0Tojesd4iNy"
      },
      "outputs": [],
      "source": [
        "# scaling the features\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "35ZVMlVB4iQS"
      },
      "outputs": [],
      "source": [
        "# create custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = torch.tensor(features,dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels,dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx],self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wej-FjC14iS0"
      },
      "outputs": [],
      "source": [
        "# Creating train and test DATASET\n",
        "train_dataset = CustomDataset(x_train.values,y_train.values)\n",
        "test_dataset = CustomDataset(x_test.values,y_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UfB6bbOc7Mru",
        "outputId": "aaa5ebc7-7d10-43bc-90e1-f4653d0d710e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.1412, 0.5216, 0.7373, 0.4510, 0.2706, 0.2784, 0.4196, 0.7294, 0.6431,\n",
              "         0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0314, 0.5922,\n",
              "         0.9569, 0.9569, 0.9529, 0.9294, 0.9804, 0.9725, 0.9647, 0.9843, 0.9451,\n",
              "         0.9451, 0.9451, 0.9608, 0.5686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.0902, 0.8980,\n",
              "         0.9961, 0.9373, 0.9059, 0.9333, 0.9490, 0.9451, 0.9529, 0.9529, 0.9490,\n",
              "         0.9529, 0.9098, 0.8941, 0.9294, 0.9961, 0.8706, 0.0941, 0.0000, 0.0118,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6627,\n",
              "         0.9804, 0.8784, 0.9098, 0.9216, 0.7529, 0.5725, 0.5098, 0.3843, 0.3686,\n",
              "         0.3686, 0.5333, 0.9451, 0.9451, 0.9020, 0.8824, 0.9765, 0.6784, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.8706, 0.9216, 0.9137, 0.9059, 1.0000, 0.3686, 0.0000, 0.0000, 0.0000,\n",
              "         0.5176, 0.4667, 0.0000, 0.1647, 0.8745, 0.9216, 0.9020, 0.9137, 0.8863,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0275, 0.9333, 0.9137, 0.9059, 0.9216, 0.8824, 0.3529, 0.2000, 0.2039,\n",
              "         0.6275, 0.7098, 1.0000, 0.1020, 0.0000, 0.4941, 0.9961, 0.9059, 0.9059,\n",
              "         0.9490, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1373, 0.9647, 0.9176, 0.9098, 0.9255, 0.8863, 0.1412, 0.0078,\n",
              "         0.0275, 0.0000, 0.2549, 0.5765, 0.0000, 0.2941, 0.0980, 0.5137, 0.9608,\n",
              "         0.9059, 0.9686, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.2706, 0.9843, 0.9216, 0.9176, 0.9333, 0.6706, 0.1098,\n",
              "         0.1373, 0.0039, 0.0000, 0.8196, 0.1804, 0.2431, 0.7098, 0.3490, 0.7412,\n",
              "         0.9569, 0.9137, 0.9765, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.4118, 0.9882, 0.9255, 0.9255, 0.9255, 0.8157,\n",
              "         0.6039, 0.6196, 0.3490, 0.1569, 0.3176, 0.6235, 0.7294, 0.7804, 0.2392,\n",
              "         0.6039, 0.9804, 0.9137, 0.9843, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 0.9216, 0.9333, 0.9647,\n",
              "         0.7804, 0.3608, 0.4627, 0.4118, 0.7255, 0.7020, 0.4549, 0.4588, 0.9804,\n",
              "         0.4941, 0.6745, 0.9843, 0.9098, 0.9961, 0.5608, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5255, 1.0000, 0.9294, 0.9373,\n",
              "         0.9843, 0.7490, 0.5686, 0.7569, 0.4824, 0.8196, 0.8824, 0.8275, 0.7098,\n",
              "         1.0000, 0.4667, 0.7059, 1.0000, 0.9137, 0.9961, 0.6196, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 1.0000, 0.9333,\n",
              "         0.9412, 0.9882, 0.7176, 0.3961, 0.6275, 0.5490, 0.9020, 0.9020, 0.9490,\n",
              "         0.7412, 1.0000, 0.5725, 0.7961, 0.9961, 0.9216, 0.9961, 0.7255, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 1.0000,\n",
              "         0.9451, 0.9373, 1.0000, 0.6980, 0.2980, 0.9373, 1.0000, 0.9098, 0.9059,\n",
              "         1.0000, 0.4549, 0.4039, 0.3686, 0.7882, 0.9961, 0.9333, 0.9804, 0.8471,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n",
              "         0.9804, 0.9765, 0.8941, 0.9608, 0.7608, 0.3765, 1.0000, 0.9020, 0.9098,\n",
              "         0.9137, 1.0000, 0.4902, 0.4196, 0.4078, 0.6549, 0.9412, 0.9569, 0.9569,\n",
              "         0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.9373, 0.9529, 0.9804, 0.8157, 0.9098, 0.8314, 0.4235, 0.5922, 0.7569,\n",
              "         0.9255, 0.9216, 0.8980, 0.2941, 0.4392, 0.3725, 0.6157, 0.8118, 0.9843,\n",
              "         0.9373, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 1.0000, 0.9373, 0.9843, 0.7529, 0.8941, 0.9569, 0.5373, 0.3765,\n",
              "         0.9882, 0.9020, 1.0000, 0.6510, 0.2784, 0.4824, 0.3922, 0.6275, 0.6627,\n",
              "         1.0000, 0.9255, 0.9176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 1.0000, 0.9294, 0.9843, 0.6784, 0.8980, 0.9804, 0.8745,\n",
              "         0.8196, 0.9922, 0.8902, 0.9922, 0.4667, 0.3569, 0.3961, 0.4549, 0.8118,\n",
              "         0.5882, 1.0000, 0.9216, 0.9451, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 1.0000, 0.9333, 1.0000, 0.5843, 0.9451, 0.9020,\n",
              "         0.9569, 0.9529, 0.9176, 0.9255, 0.9804, 0.4902, 0.4549, 0.5765, 0.9176,\n",
              "         1.0000, 0.3843, 1.0000, 0.9216, 0.9529, 0.2118, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0549, 0.9333, 0.9373, 0.9922, 0.5059, 0.9804,\n",
              "         0.8980, 0.9216, 0.9098, 0.8980, 0.8902, 0.9059, 0.8902, 0.8471, 0.9804,\n",
              "         0.9882, 0.9765, 0.2863, 1.0000, 0.9294, 0.9608, 0.2824, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.9373, 0.9373, 0.9490, 0.4588,\n",
              "         1.0000, 0.8941, 0.9373, 0.9255, 0.9216, 0.9255, 0.9137, 0.9490, 0.9451,\n",
              "         0.9333, 0.8863, 1.0000, 0.3137, 0.9961, 0.9373, 0.9647, 0.3255, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2549, 0.9529, 0.9529, 0.9176,\n",
              "         0.4588, 1.0000, 0.8941, 0.9294, 0.9255, 0.9255, 0.9216, 0.9176, 0.9098,\n",
              "         0.9137, 0.9098, 0.8863, 1.0000, 0.3412, 0.9490, 0.9451, 0.9608, 0.3294,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608, 0.9608, 0.9647,\n",
              "         0.7765, 0.4157, 1.0000, 0.8902, 0.9294, 0.9255, 0.9216, 0.9216, 0.9137,\n",
              "         0.9176, 0.9216, 0.9176, 0.8667, 1.0000, 0.3412, 0.8510, 0.9608, 0.9569,\n",
              "         0.3451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.9569,\n",
              "         0.9804, 0.6353, 0.4000, 1.0000, 0.8941, 0.9255, 0.9216, 0.9216, 0.9216,\n",
              "         0.9176, 0.9176, 0.9216, 0.9216, 0.8706, 1.0000, 0.3216, 0.7059, 0.9804,\n",
              "         0.9529, 0.3647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4863,\n",
              "         0.9569, 0.9961, 0.4784, 0.3922, 1.0000, 0.9059, 0.9255, 0.9255, 0.9216,\n",
              "         0.9294, 0.9294, 0.9294, 0.9333, 0.9294, 0.9020, 1.0000, 0.2824, 0.5098,\n",
              "         0.9922, 0.9608, 0.3843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.5961, 0.9373, 1.0000, 0.4078, 0.3843, 0.9804, 0.8980, 0.9059, 0.9098,\n",
              "         0.9059, 0.9098, 0.9098, 0.9098, 0.9098, 0.9020, 0.8941, 0.9843, 0.1490,\n",
              "         0.5333, 1.0000, 0.9529, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.6314, 0.9333, 0.9961, 0.1294, 0.3725, 1.0000, 0.9608, 0.9843,\n",
              "         0.9843, 0.9843, 0.9882, 0.9882, 0.9882, 0.9882, 0.9843, 0.9804, 1.0000,\n",
              "         0.0000, 0.5569, 0.9961, 0.9294, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.6118, 0.9961, 1.0000, 0.2588, 0.0000, 0.3529, 0.2627,\n",
              "         0.2824, 0.2902, 0.3098, 0.3255, 0.3373, 0.3529, 0.3608, 0.3882, 0.3961,\n",
              "         0.4902, 0.0000, 0.5412, 1.0000, 0.9765, 0.5882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3294, 0.7451, 0.7333, 0.1922, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3490, 0.8275, 0.8275, 0.3647, 0.0000, 0.0000,\n",
              "         0.0000]),\n",
              " tensor(2))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[6]  # shows the dataset of 1st image and its label in a tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FkJlduP47Mue"
      },
      "outputs": [],
      "source": [
        "# create TRAIN and TEST DATA LOADER\n",
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False) # during the testing phase data should not shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "n2nTeKBC7MxG"
      },
      "outputs": [],
      "source": [
        "# define NN class\n",
        "\n",
        "# in this-> 1st layer: 784 conn enters and 128 exits activation fn is ReLU and so on....\n",
        "\n",
        "class nn_model(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super(nn_model,self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,features):\n",
        "    return self.model(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9_K2fA4P7M0i"
      },
      "outputs": [],
      "source": [
        "# learning rate and epochs\n",
        "epochs = 100\n",
        "lr = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0g6MAKpK-I9u"
      },
      "outputs": [],
      "source": [
        "# obj of class , loss fn , optimizer\n",
        "model = nn_model(x_train.shape[1])\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "64Scpzay-JAW",
        "outputId": "e335f4d9-77e5-4a99-db12-a76a2c898785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 1.299172268111325\n",
            "Epoch 2/100, Loss: 0.777664680805432\n",
            "Epoch 3/100, Loss: 0.6580859629007486\n",
            "Epoch 4/100, Loss: 0.5859024880905829\n",
            "Epoch 5/100, Loss: 0.5418627020522687\n",
            "Epoch 6/100, Loss: 0.4977797763587455\n",
            "Epoch 7/100, Loss: 0.47541967298857557\n",
            "Epoch 8/100, Loss: 0.44925747150500145\n",
            "Epoch 9/100, Loss: 0.43655581569530555\n",
            "Epoch 10/100, Loss: 0.40646887134165455\n",
            "Epoch 11/100, Loss: 0.39233429606496933\n",
            "Epoch 12/100, Loss: 0.37642328163399497\n",
            "Epoch 13/100, Loss: 0.35150069664039557\n",
            "Epoch 14/100, Loss: 0.32991928214857563\n",
            "Epoch 15/100, Loss: 0.3401900088998693\n",
            "Epoch 16/100, Loss: 0.30734775047859497\n",
            "Epoch 17/100, Loss: 0.29790962361813295\n",
            "Epoch 18/100, Loss: 0.2904092372345501\n",
            "Epoch 19/100, Loss: 0.27739772665694623\n",
            "Epoch 20/100, Loss: 0.2669351102685082\n",
            "Epoch 21/100, Loss: 0.25889220342216407\n",
            "Epoch 22/100, Loss: 0.24022076757261035\n",
            "Epoch 23/100, Loss: 0.24594975344439934\n",
            "Epoch 24/100, Loss: 0.23756213882971092\n",
            "Epoch 25/100, Loss: 0.23868792951547887\n",
            "Epoch 26/100, Loss: 0.2237994206198574\n",
            "Epoch 27/100, Loss: 0.2025538986251199\n",
            "Epoch 28/100, Loss: 0.20932344755036592\n",
            "Epoch 29/100, Loss: 0.20001222833594273\n",
            "Epoch 30/100, Loss: 0.1986087925467618\n",
            "Epoch 31/100, Loss: 0.1943521007630952\n",
            "Epoch 32/100, Loss: 0.17675807864884652\n",
            "Epoch 33/100, Loss: 0.16884006511353883\n",
            "Epoch 34/100, Loss: 0.17192586526803716\n",
            "Epoch 35/100, Loss: 0.16710618773155664\n",
            "Epoch 36/100, Loss: 0.15913719474475765\n",
            "Epoch 37/100, Loss: 0.15977427202480785\n",
            "Epoch 38/100, Loss: 0.14743517932189992\n",
            "Epoch 39/100, Loss: 0.1438165907610274\n",
            "Epoch 40/100, Loss: 0.13042423221111826\n",
            "Epoch 41/100, Loss: 0.17212424807515017\n",
            "Epoch 42/100, Loss: 0.12328148688349498\n",
            "Epoch 43/100, Loss: 0.12721044755369953\n",
            "Epoch 44/100, Loss: 0.12750926500836596\n",
            "Epoch 45/100, Loss: 0.11056089062331872\n",
            "Epoch 46/100, Loss: 0.10291058356879201\n",
            "Epoch 47/100, Loss: 0.10509572904997852\n",
            "Epoch 48/100, Loss: 0.1134737305089655\n",
            "Epoch 49/100, Loss: 0.095208572058459\n",
            "Epoch 50/100, Loss: 0.10755860690611618\n",
            "Epoch 51/100, Loss: 0.10370622052034066\n",
            "Epoch 52/100, Loss: 0.09494565330313508\n",
            "Epoch 53/100, Loss: 0.08458926912518383\n",
            "Epoch 54/100, Loss: 0.08922601341319507\n",
            "Epoch 55/100, Loss: 0.08564074882361267\n",
            "Epoch 56/100, Loss: 0.08427194929158194\n",
            "Epoch 57/100, Loss: 0.0776174685431468\n",
            "Epoch 58/100, Loss: 0.08584597882037685\n",
            "Epoch 59/100, Loss: 0.09039712117774104\n",
            "Epoch 60/100, Loss: 0.07652432926015697\n",
            "Epoch 61/100, Loss: 0.07485381368349289\n",
            "Epoch 62/100, Loss: 0.07485593527627106\n",
            "Epoch 63/100, Loss: 0.06777299295307672\n",
            "Epoch 64/100, Loss: 0.05627148474853199\n",
            "Epoch 65/100, Loss: 0.07255350181091709\n",
            "Epoch 66/100, Loss: 0.04647603787663641\n",
            "Epoch 67/100, Loss: 0.06920400234462815\n",
            "Epoch 68/100, Loss: 0.04699192541932478\n",
            "Epoch 69/100, Loss: 0.049821048999789376\n",
            "Epoch 70/100, Loss: 0.0441035820293852\n",
            "Epoch 71/100, Loss: 0.045015133696900314\n",
            "Epoch 72/100, Loss: 0.049008584163873596\n",
            "Epoch 73/100, Loss: 0.06278451299983677\n",
            "Epoch 74/100, Loss: 0.059914355949476666\n",
            "Epoch 75/100, Loss: 0.08161662657987657\n",
            "Epoch 76/100, Loss: 0.043558421732786186\n",
            "Epoch 77/100, Loss: 0.04238839654841587\n",
            "Epoch 78/100, Loss: 0.026754389290378246\n",
            "Epoch 79/100, Loss: 0.030144966276329472\n",
            "Epoch 80/100, Loss: 0.04707015272830586\n",
            "Epoch 81/100, Loss: 0.0966861149022003\n",
            "Epoch 82/100, Loss: 0.04729110436354207\n",
            "Epoch 83/100, Loss: 0.05785597666420219\n",
            "Epoch 84/100, Loss: 0.026694360745040224\n",
            "Epoch 85/100, Loss: 0.020213777622856893\n",
            "Epoch 86/100, Loss: 0.04462243273121321\n",
            "Epoch 87/100, Loss: 0.013515340496672967\n",
            "Epoch 88/100, Loss: 0.0784172425273883\n",
            "Epoch 89/100, Loss: 0.03953138985581553\n",
            "Epoch 90/100, Loss: 0.06436323239013399\n",
            "Epoch 91/100, Loss: 0.054044652308651506\n",
            "Epoch 92/100, Loss: 0.02630842344204416\n",
            "Epoch 93/100, Loss: 0.05063757808918971\n",
            "Epoch 94/100, Loss: 0.0504689325915013\n",
            "Epoch 95/100, Loss: 0.0416439633896387\n",
            "Epoch 96/100, Loss: 0.023825650189496225\n",
            "Epoch 97/100, Loss: 0.015699108942865102\n",
            "Epoch 98/100, Loss: 0.01762844640647954\n",
            "Epoch 99/100, Loss: 0.12168132017446494\n",
            "Epoch 100/100, Loss: 0.04215682491166903\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "for i in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    # forward pass\n",
        "    output = model(batch_features)\n",
        "    # calculate loss\n",
        "    loss = loss_fn(output,batch_labels)\n",
        "    # clear grads\n",
        "    optimizer.zero_grad()\n",
        "    # back pass\n",
        "    loss.backward()\n",
        "    # update grads\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "  print(f'Epoch {i+1}/{epochs}, Loss: {total_loss/len(train_loader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LNgJeUr-JC3",
        "outputId": "a89519c9-78a3-42d1-fbf0-9c7ca5bd23d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nn_model(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# telling the model to go into evaluation phase\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0V2VPlK-JGQ",
        "outputId": "8358564d-20e6-45d3-c23f-e4b3a08e6782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.0\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    output = model(batch_features)\n",
        "    _,pred_val = torch.max(output,1)\n",
        "    total += batch_labels.size(0)\n",
        "    correct = correct + (pred_val==batch_labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100*correct/total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kp9W1x-C9wS"
      },
      "source": [
        "# TRAINING FULL DATASET ON GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PAUD1lC44iVb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "L4djFqhXDIJ3",
        "outputId": "6f674c28-a81a-499e-b229-80aa63886a4b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-459ba596-02f4-4192-82cf-1da564e77dd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-459ba596-02f4-4192-82cf-1da564e77dd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-459ba596-02f4-4192-82cf-1da564e77dd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-459ba596-02f4-4192-82cf-1da564e77dd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f27be31a-51fc-491a-a06f-15595ac2d2ef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f27be31a-51fc-491a-a06f-15595ac2d2ef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f27be31a-51fc-491a-a06f-15595ac2d2ef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0        30        43         0   \n",
              "3       0  ...         3         0         0         0         0         1   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('/content/fashion-mnist_train.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYR77iYODIMY",
        "outputId": "30dba5ab-472d-4c2b-908f-60d7288efaec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "vNCbmm6cDIO9",
        "outputId": "b9cf7c5f-1d95-4f8f-8cba-9f7d7649b267"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a77cc72b-dc8d-43db-b540-79e7d7657cfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a77cc72b-dc8d-43db-b540-79e7d7657cfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a77cc72b-dc8d-43db-b540-79e7d7657cfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a77cc72b-dc8d-43db-b540-79e7d7657cfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-332c1714-9050-474d-b347-6d8548a801e0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-332c1714-9050-474d-b347-6d8548a801e0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-332c1714-9050-474d-b347-6d8548a801e0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      0       0       0       0       0       0       0       0       9   \n",
              "1      1       0       0       0       0       0       0       0       0   \n",
              "2      2       0       0       0       0       0       0      14      53   \n",
              "3      2       0       0       0       0       0       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       8  ...       103        87        56         0         0         0   \n",
              "1       0  ...        34         0         0         0         0         0   \n",
              "2      99  ...         0         0         0         0        63        53   \n",
              "3       0  ...       137       126       140         0       133       224   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2        31         0         0         0  \n",
              "3       222        56         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv('/content/fashion-mnist_test.csv')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uoh49NopDIRh"
      },
      "outputs": [],
      "source": [
        "x_train , y_train = train.iloc[:,1:],train.iloc[:,0]\n",
        "x_test , y_test = test.iloc[:,1:],test.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYO7FwrcDIUN",
        "outputId": "fd8a1c7b-c1e0-4ced-8937-c84e9bb19c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# check for gpu (cuda means GPU is being used)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XVJg7fsnDIWl"
      },
      "outputs": [],
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "A5f5Bmq3DIZF"
      },
      "outputs": [],
      "source": [
        "class myDataset(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = torch.tensor(features.values,dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels.values,dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx],self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jnQUDmNnDIbt"
      },
      "outputs": [],
      "source": [
        "train_dataset = myDataset(x_train,y_train)\n",
        "test_dataset = myDataset(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OD0qsEoFDIeP"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YUDAwLTrDIg3"
      },
      "outputs": [],
      "source": [
        "class myNN(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super(myNN,self).__init__()\n",
        "    self.model = nn.Sequential(nn.Linear(num_features,256),nn.ReLU(),nn.Linear(256,128),nn.ReLU(),nn.Linear(128,10))\n",
        "\n",
        "  def forward(self,features):\n",
        "    return self.model(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nmoztnOUDIjn"
      },
      "outputs": [],
      "source": [
        "lr = 0.1\n",
        "epochs = 170\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# MOVE THE MODEL TO GPU\n",
        "model = myNN(x_train.shape[1]).to(device)\n",
        "optimizer = optim.SGD(model.parameters(),lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4jONSfkNDImP",
        "outputId": "23c3c06c-2983-4f13-e0fd-4c526c77e01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/170, Loss: 0.5961014026403427\n",
            "Epoch 2/170, Loss: 0.4077127419511477\n",
            "Epoch 3/170, Loss: 0.3654175465087096\n",
            "Epoch 4/170, Loss: 0.3360407194674015\n",
            "Epoch 5/170, Loss: 0.3168120200792948\n",
            "Epoch 6/170, Loss: 0.30113830135862035\n",
            "Epoch 7/170, Loss: 0.2877857552190622\n",
            "Epoch 8/170, Loss: 0.27622730354368685\n",
            "Epoch 9/170, Loss: 0.2661638409227133\n",
            "Epoch 10/170, Loss: 0.25554275271693866\n",
            "Epoch 11/170, Loss: 0.24602291658222675\n",
            "Epoch 12/170, Loss: 0.237036546660463\n",
            "Epoch 13/170, Loss: 0.23115031337340672\n",
            "Epoch 14/170, Loss: 0.22429758493900298\n",
            "Epoch 15/170, Loss: 0.21642751393417517\n",
            "Epoch 16/170, Loss: 0.20974124344388645\n",
            "Epoch 17/170, Loss: 0.2026915232439836\n",
            "Epoch 18/170, Loss: 0.19854561660488446\n",
            "Epoch 19/170, Loss: 0.19207192780673504\n",
            "Epoch 20/170, Loss: 0.18652737194001676\n",
            "Epoch 21/170, Loss: 0.1812101836686333\n",
            "Epoch 22/170, Loss: 0.17788494912683964\n",
            "Epoch 23/170, Loss: 0.17177383943398794\n",
            "Epoch 24/170, Loss: 0.1681931316634019\n",
            "Epoch 25/170, Loss: 0.16664916855196157\n",
            "Epoch 26/170, Loss: 0.16001543573836485\n",
            "Epoch 27/170, Loss: 0.15582677904566128\n",
            "Epoch 28/170, Loss: 0.1538367019114395\n",
            "Epoch 29/170, Loss: 0.1479525282859802\n",
            "Epoch 30/170, Loss: 0.14397243679265181\n",
            "Epoch 31/170, Loss: 0.14129072462276865\n",
            "Epoch 32/170, Loss: 0.13699157953802496\n",
            "Epoch 33/170, Loss: 0.13493091496936976\n",
            "Epoch 34/170, Loss: 0.13108969025313855\n",
            "Epoch 35/170, Loss: 0.1253026066935621\n",
            "Epoch 36/170, Loss: 0.12460962480679154\n",
            "Epoch 37/170, Loss: 0.12068031386171157\n",
            "Epoch 38/170, Loss: 0.12001922033516069\n",
            "Epoch 39/170, Loss: 0.11771457185503095\n",
            "Epoch 40/170, Loss: 0.11383042244731138\n",
            "Epoch 41/170, Loss: 0.11075186929975947\n",
            "Epoch 42/170, Loss: 0.10647208828665317\n",
            "Epoch 43/170, Loss: 0.10687021140220265\n",
            "Epoch 44/170, Loss: 0.10442218767454227\n",
            "Epoch 45/170, Loss: 0.09839251796280345\n",
            "Epoch 46/170, Loss: 0.0985843906433632\n",
            "Epoch 47/170, Loss: 0.09784333211363604\n",
            "Epoch 48/170, Loss: 0.09955662564318628\n",
            "Epoch 49/170, Loss: 0.09750540991878758\n",
            "Epoch 50/170, Loss: 0.0912964681636542\n",
            "Epoch 51/170, Loss: 0.08860943309807529\n",
            "Epoch 52/170, Loss: 0.08864600661766404\n",
            "Epoch 53/170, Loss: 0.08714841211549938\n",
            "Epoch 54/170, Loss: 0.08239535334712515\n",
            "Epoch 55/170, Loss: 0.0815247171079119\n",
            "Epoch 56/170, Loss: 0.07808932600157956\n",
            "Epoch 57/170, Loss: 0.0830549784239071\n",
            "Epoch 58/170, Loss: 0.08288038937519304\n",
            "Epoch 59/170, Loss: 0.08231609351763812\n",
            "Epoch 60/170, Loss: 0.07333842799674409\n",
            "Epoch 61/170, Loss: 0.0726194581797036\n",
            "Epoch 62/170, Loss: 0.07527730519029623\n",
            "Epoch 63/170, Loss: 0.0700696624798545\n",
            "Epoch 64/170, Loss: 0.06649914161553606\n",
            "Epoch 65/170, Loss: 0.0661002108340462\n",
            "Epoch 66/170, Loss: 0.06541019647217666\n",
            "Epoch 67/170, Loss: 0.06652631897374522\n",
            "Epoch 68/170, Loss: 0.06630489592322458\n",
            "Epoch 69/170, Loss: 0.05889614460545903\n",
            "Epoch 70/170, Loss: 0.06061251475912674\n",
            "Epoch 71/170, Loss: 0.058958921210180655\n",
            "Epoch 72/170, Loss: 0.055014986233219196\n",
            "Epoch 73/170, Loss: 0.058755347827839435\n",
            "Epoch 74/170, Loss: 0.06586753782980764\n",
            "Epoch 75/170, Loss: 0.059029544473222145\n",
            "Epoch 76/170, Loss: 0.059622741583963704\n",
            "Epoch 77/170, Loss: 0.05442241720635211\n",
            "Epoch 78/170, Loss: 0.05467827593621817\n",
            "Epoch 79/170, Loss: 0.05254963687798397\n",
            "Epoch 80/170, Loss: 0.0518966043628209\n",
            "Epoch 81/170, Loss: 0.04268256176695383\n",
            "Epoch 82/170, Loss: 0.0553769490526213\n",
            "Epoch 83/170, Loss: 0.04802005792821292\n",
            "Epoch 84/170, Loss: 0.05145458874081184\n",
            "Epoch 85/170, Loss: 0.046926077820073506\n",
            "Epoch 86/170, Loss: 0.04819409054548014\n",
            "Epoch 87/170, Loss: 0.04855512626216514\n",
            "Epoch 88/170, Loss: 0.045406204319677394\n",
            "Epoch 89/170, Loss: 0.0443418151201137\n",
            "Epoch 90/170, Loss: 0.0440358757001212\n",
            "Epoch 91/170, Loss: 0.04122878200221264\n",
            "Epoch 92/170, Loss: 0.03427767455105156\n",
            "Epoch 93/170, Loss: 0.03925955219387567\n",
            "Epoch 94/170, Loss: 0.04380971811945043\n",
            "Epoch 95/170, Loss: 0.03948003760554105\n",
            "Epoch 96/170, Loss: 0.03754715001378597\n",
            "Epoch 97/170, Loss: 0.03644255277063543\n",
            "Epoch 98/170, Loss: 0.03256156640285238\n",
            "Epoch 99/170, Loss: 0.046161244215930736\n",
            "Epoch 100/170, Loss: 0.040849382314441025\n",
            "Epoch 101/170, Loss: 0.043512633267152705\n",
            "Epoch 102/170, Loss: 0.03491260126505222\n",
            "Epoch 103/170, Loss: 0.04237568124390867\n",
            "Epoch 104/170, Loss: 0.03840296221938916\n",
            "Epoch 105/170, Loss: 0.03672260624750634\n",
            "Epoch 106/170, Loss: 0.026456077787441124\n",
            "Epoch 107/170, Loss: 0.03485609218904477\n",
            "Epoch 108/170, Loss: 0.023805103044229812\n",
            "Epoch 109/170, Loss: 0.03962546042770094\n",
            "Epoch 110/170, Loss: 0.04811554795909421\n",
            "Epoch 111/170, Loss: 0.024963846526952695\n",
            "Epoch 112/170, Loss: 0.03308195181503385\n",
            "Epoch 113/170, Loss: 0.029969194039187276\n",
            "Epoch 114/170, Loss: 0.024544727273250706\n",
            "Epoch 115/170, Loss: 0.02651042982967774\n",
            "Epoch 116/170, Loss: 0.0308973935154451\n",
            "Epoch 117/170, Loss: 0.022335308504584282\n",
            "Epoch 118/170, Loss: 0.03814989931696741\n",
            "Epoch 119/170, Loss: 0.03717818958222136\n",
            "Epoch 120/170, Loss: 0.03640447961298875\n",
            "Epoch 121/170, Loss: 0.02742304267318929\n",
            "Epoch 122/170, Loss: 0.026010247454597266\n",
            "Epoch 123/170, Loss: 0.025684539650745925\n",
            "Epoch 124/170, Loss: 0.028339480968772115\n",
            "Epoch 125/170, Loss: 0.030755918180074757\n",
            "Epoch 126/170, Loss: 0.022343406761136126\n",
            "Epoch 127/170, Loss: 0.02182495655044962\n",
            "Epoch 128/170, Loss: 0.025407492336402597\n",
            "Epoch 129/170, Loss: 0.024342831262008015\n",
            "Epoch 130/170, Loss: 0.01663426778164685\n",
            "Epoch 131/170, Loss: 0.036234681233745715\n",
            "Epoch 132/170, Loss: 0.026651594753185782\n",
            "Epoch 133/170, Loss: 0.019932836451649685\n",
            "Epoch 134/170, Loss: 0.00908517596229285\n",
            "Epoch 135/170, Loss: 0.027328842919329813\n",
            "Epoch 136/170, Loss: 0.02257145872294665\n",
            "Epoch 137/170, Loss: 0.019958869187141744\n",
            "Epoch 138/170, Loss: 0.03538547239077937\n",
            "Epoch 139/170, Loss: 0.02805248334339946\n",
            "Epoch 140/170, Loss: 0.011432699686788556\n",
            "Epoch 141/170, Loss: 0.012063052697339814\n",
            "Epoch 142/170, Loss: 0.011231592618046397\n",
            "Epoch 143/170, Loss: 0.009039150080951436\n",
            "Epoch 144/170, Loss: 0.004904090597378126\n",
            "Epoch 145/170, Loss: 0.0016603368096730112\n",
            "Epoch 146/170, Loss: 0.002493203548860674\n",
            "Epoch 147/170, Loss: 0.006488230951383472\n",
            "Epoch 148/170, Loss: 0.0024064337470802344\n",
            "Epoch 149/170, Loss: 0.002193321672739012\n",
            "Epoch 150/170, Loss: 0.0011290003609195386\n",
            "Epoch 151/170, Loss: 0.0008045801712643538\n",
            "Epoch 152/170, Loss: 0.0005770765524875894\n",
            "Epoch 153/170, Loss: 0.00046610454236164665\n",
            "Epoch 154/170, Loss: 0.00039972169009083036\n",
            "Epoch 155/170, Loss: 0.00033670267983227406\n",
            "Epoch 156/170, Loss: 0.0003174852792109533\n",
            "Epoch 157/170, Loss: 0.00029256498551284975\n",
            "Epoch 158/170, Loss: 0.00027071818188318276\n",
            "Epoch 159/170, Loss: 0.00025604212292753913\n",
            "Epoch 160/170, Loss: 0.0002503898700497795\n",
            "Epoch 161/170, Loss: 0.0002355322833200996\n",
            "Epoch 162/170, Loss: 0.00022024443649963434\n",
            "Epoch 163/170, Loss: 0.00021281935287644985\n",
            "Epoch 164/170, Loss: 0.00020516174390786333\n",
            "Epoch 165/170, Loss: 0.0001980442423108034\n",
            "Epoch 166/170, Loss: 0.00019077098309182173\n",
            "Epoch 167/170, Loss: 0.0001848831639702354\n",
            "Epoch 168/170, Loss: 0.00017749183441637608\n",
            "Epoch 169/170, Loss: 0.0001745819842119431\n",
            "Epoch 170/170, Loss: 0.00016750436605342795\n"
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_features,batch_labels in train_loader:\n",
        "    # MOVE THE FEATURES AND LABELS TO GPU\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    loss = loss_fn(output,batch_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f'Epoch {i+1}/{epochs}, Loss: {total_loss/len(train_loader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59S4rLuVDIph",
        "outputId": "3a0c5c34-230e-4fa5-8142-9cfa82add518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 90.96\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "    output = model(batch_features)\n",
        "    _,pred_val = torch.max(output,1)\n",
        "    total += batch_labels.size(0)\n",
        "    correct = correct + (pred_val==batch_labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100*correct/total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDBmncNr4iX_"
      },
      "outputs": [],
      "source": [
        "# TEST ACC -> 90.96%  and TRAIN ACC -> 100%   ->  OVERFITTING\n",
        "\n",
        "# STEPS TO IMPROVE THE ACCURACY ->\n",
        "'''\n",
        "1) Adding more data\n",
        "2) Regularization (l1/l2 methods)\n",
        "3) Dropouts (randomly turn off some neurons during training)\n",
        "4) Data Augmentation (Make some changes in data to reduce overfitting) -> (flip or rotate ur images for this case) USUALLY PREFERRED IN CNN\n",
        "5) Batch Normalization (Take batch of outputs and normalize it before sending them to activation functions)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3-QNi9mu4ibh"
      },
      "outputs": [],
      "source": [
        "class myNN(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super(myNN,self).__init__()\n",
        "    self.model = nn.Sequential(nn.Linear(num_features,256),\n",
        "                               nn.BatchNorm1d(256),  # applying Batch Normalization\n",
        "                               nn.ReLU(),\n",
        "                               nn.Dropout(0.3),  # adding nn.dropout(0.3) for DROPOUT\n",
        "                               nn.Linear(256,128),\n",
        "                               nn.BatchNorm1d(128),  # applying Batch Normalization\n",
        "                               nn.ReLU(),\n",
        "                               nn.Dropout(0.3),  # adding nn.dropout(0.3) for DROPOUT\n",
        "                               nn.Linear(128,10))\n",
        "\n",
        "  def forward(self,features):\n",
        "    return self.model(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Qh8G2pxEfxAo"
      },
      "outputs": [],
      "source": [
        "lr = 0.1\n",
        "epochs = 100\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# MOVE THE MODEL TO GPU\n",
        "model = myNN(x_train.shape[1]).to(device)\n",
        "# USING L2 REGULARIZATION (adding lambda(m**2) term to the loss fn) by weight_decay=1e-4 (i.e lambda = 1e-4)\n",
        "optimizer = optim.SGD(model.parameters(),lr=lr,weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hKgHc7VNfxEB",
        "outputId": "bc67f7c2-74e0-4fa1-c6ff-bfd03acad3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 0.5579717110792796\n",
            "Epoch 2/100, Loss: 0.442810502521197\n",
            "Epoch 3/100, Loss: 0.40552687798341114\n",
            "Epoch 4/100, Loss: 0.3831835290471713\n",
            "Epoch 5/100, Loss: 0.3636744214296341\n",
            "Epoch 6/100, Loss: 0.3521324602882067\n",
            "Epoch 7/100, Loss: 0.34141615504821143\n",
            "Epoch 8/100, Loss: 0.3310826453765233\n",
            "Epoch 9/100, Loss: 0.326000748082002\n",
            "Epoch 10/100, Loss: 0.31563529765208564\n",
            "Epoch 11/100, Loss: 0.309834915548563\n",
            "Epoch 12/100, Loss: 0.30398073585629465\n",
            "Epoch 13/100, Loss: 0.3025985496580601\n",
            "Epoch 14/100, Loss: 0.29518686702052754\n",
            "Epoch 15/100, Loss: 0.29019422934452693\n",
            "Epoch 16/100, Loss: 0.2860689706603686\n",
            "Epoch 17/100, Loss: 0.28294800273974735\n",
            "Epoch 18/100, Loss: 0.2784907188574473\n",
            "Epoch 19/100, Loss: 0.27559303075472513\n",
            "Epoch 20/100, Loss: 0.2734107196350892\n",
            "Epoch 21/100, Loss: 0.26998722185095153\n",
            "Epoch 22/100, Loss: 0.2653153003931046\n",
            "Epoch 23/100, Loss: 0.26558858999808627\n",
            "Epoch 24/100, Loss: 0.26139304039676986\n",
            "Epoch 25/100, Loss: 0.26014718617399535\n",
            "Epoch 26/100, Loss: 0.25679663872321445\n",
            "Epoch 27/100, Loss: 0.2566405991256237\n",
            "Epoch 28/100, Loss: 0.2510102012614409\n",
            "Epoch 29/100, Loss: 0.25243239704370496\n",
            "Epoch 30/100, Loss: 0.251899835729599\n",
            "Epoch 31/100, Loss: 0.24821083318988482\n",
            "Epoch 32/100, Loss: 0.24810509447455406\n",
            "Epoch 33/100, Loss: 0.2460381648997466\n",
            "Epoch 34/100, Loss: 0.24233139557639757\n",
            "Epoch 35/100, Loss: 0.2412342464665572\n",
            "Epoch 36/100, Loss: 0.24501280863483746\n",
            "Epoch 37/100, Loss: 0.23910047189593314\n",
            "Epoch 38/100, Loss: 0.24075834543903668\n",
            "Epoch 39/100, Loss: 0.23625180775721868\n",
            "Epoch 40/100, Loss: 0.23519562981128692\n",
            "Epoch 41/100, Loss: 0.23480216354926428\n",
            "Epoch 42/100, Loss: 0.2374127104083697\n",
            "Epoch 43/100, Loss: 0.2313866587261359\n",
            "Epoch 44/100, Loss: 0.23538514498670896\n",
            "Epoch 45/100, Loss: 0.22993412121435006\n",
            "Epoch 46/100, Loss: 0.23055132098893324\n",
            "Epoch 47/100, Loss: 0.23180422181487084\n",
            "Epoch 48/100, Loss: 0.2279829694847266\n",
            "Epoch 49/100, Loss: 0.2285471106092135\n",
            "Epoch 50/100, Loss: 0.22587798175811769\n",
            "Epoch 51/100, Loss: 0.22425562205712002\n",
            "Epoch 52/100, Loss: 0.22364169196883837\n",
            "Epoch 53/100, Loss: 0.22160890906453132\n",
            "Epoch 54/100, Loss: 0.22336437574923038\n",
            "Epoch 55/100, Loss: 0.2219538884282112\n",
            "Epoch 56/100, Loss: 0.22270992110172907\n",
            "Epoch 57/100, Loss: 0.21916643355985482\n",
            "Epoch 58/100, Loss: 0.22304329847892126\n",
            "Epoch 59/100, Loss: 0.22110751604437828\n",
            "Epoch 60/100, Loss: 0.2183939756333828\n",
            "Epoch 61/100, Loss: 0.2167653086791436\n",
            "Epoch 62/100, Loss: 0.21938121405939262\n",
            "Epoch 63/100, Loss: 0.2161554207180937\n",
            "Epoch 64/100, Loss: 0.21908293633361658\n",
            "Epoch 65/100, Loss: 0.21392581232736507\n",
            "Epoch 66/100, Loss: 0.21366112197240195\n",
            "Epoch 67/100, Loss: 0.21589991909066836\n",
            "Epoch 68/100, Loss: 0.213571608543396\n",
            "Epoch 69/100, Loss: 0.21411198718945185\n",
            "Epoch 70/100, Loss: 0.2133696453034878\n",
            "Epoch 71/100, Loss: 0.21226159725785254\n",
            "Epoch 72/100, Loss: 0.2137690106987953\n",
            "Epoch 73/100, Loss: 0.21079774062037468\n",
            "Epoch 74/100, Loss: 0.2111060187200705\n",
            "Epoch 75/100, Loss: 0.20793173112074534\n",
            "Epoch 76/100, Loss: 0.21133556523720423\n",
            "Epoch 77/100, Loss: 0.2082612472931544\n",
            "Epoch 78/100, Loss: 0.20828467940092088\n",
            "Epoch 79/100, Loss: 0.21010855016311009\n",
            "Epoch 80/100, Loss: 0.20929928136467935\n",
            "Epoch 81/100, Loss: 0.20895469075093667\n",
            "Epoch 82/100, Loss: 0.20744278346995512\n",
            "Epoch 83/100, Loss: 0.2041707591056824\n",
            "Epoch 84/100, Loss: 0.20921348739067713\n",
            "Epoch 85/100, Loss: 0.20460959309140841\n",
            "Epoch 86/100, Loss: 0.2044593143761158\n",
            "Epoch 87/100, Loss: 0.2048119132677714\n",
            "Epoch 88/100, Loss: 0.20579313583374023\n",
            "Epoch 89/100, Loss: 0.2060378196770946\n",
            "Epoch 90/100, Loss: 0.2023089967429638\n",
            "Epoch 91/100, Loss: 0.20443176059226195\n",
            "Epoch 92/100, Loss: 0.20361782898108163\n",
            "Epoch 93/100, Loss: 0.2028738349745671\n",
            "Epoch 94/100, Loss: 0.20408031808088223\n",
            "Epoch 95/100, Loss: 0.1999717757637302\n",
            "Epoch 96/100, Loss: 0.20362241782744725\n",
            "Epoch 97/100, Loss: 0.20206721386114757\n",
            "Epoch 98/100, Loss: 0.2024011263291041\n",
            "Epoch 99/100, Loss: 0.2004535696864128\n",
            "Epoch 100/100, Loss: 0.20250226540118457\n"
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_features,batch_labels in train_loader:\n",
        "    # MOVE THE FEATURES AND LABELS TO GPU\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    loss = loss_fn(output,batch_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f'Epoch {i+1}/{epochs}, Loss: {total_loss/len(train_loader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uwA4tsfxJp",
        "outputId": "8b1aa8a3-8d85-418d-94f6-9e75dd13e981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 95.53666666666666\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "    output = model(batch_features)\n",
        "    _,pred_val = torch.max(output,1)\n",
        "    total += batch_labels.size(0)\n",
        "    correct = correct + (pred_val==batch_labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100*correct/total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l39eJba-fxMa"
      },
      "outputs": [],
      "source": [
        "# test acc -> 90%  AND  train acc -> 95%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVrDH1yNlkyg"
      },
      "source": [
        "# HYPER PARAMETER TUNING USING ***OPTUNA***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc5ucitIluGr"
      },
      "outputs": [],
      "source": [
        "# everything till data loader is same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dga4352Zl9vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "61HYJS7Tl9vz",
        "outputId": "1d4be816-3030-41c6-9c4a-4ac68138223d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0        30        43         0   \n",
              "3       0  ...         3         0         0         0         0         1   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(\"D:\\\\Python\\\\ann\\\\fashion-mnist_train.csv\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE-5iDHcl9v0",
        "outputId": "f7fa2ceb-e7b4-40b9-9e2a-02cb5b3eda76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "eXK8EH9kl9v0",
        "outputId": "3a67b44f-60f1-4af3-afe0-ce82a42a67ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      0       0       0       0       0       0       0       0       9   \n",
              "1      1       0       0       0       0       0       0       0       0   \n",
              "2      2       0       0       0       0       0       0      14      53   \n",
              "3      2       0       0       0       0       0       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       8  ...       103        87        56         0         0         0   \n",
              "1       0  ...        34         0         0         0         0         0   \n",
              "2      99  ...         0         0         0         0        63        53   \n",
              "3       0  ...       137       126       140         0       133       224   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2        31         0         0         0  \n",
              "3       222        56         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(\"D:\\\\Python\\\\ann\\\\fashion-mnist_test.csv\")\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9I22z2_El9v0"
      },
      "outputs": [],
      "source": [
        "x_train , y_train = train.iloc[:,1:],train.iloc[:,0]\n",
        "x_test , y_test = test.iloc[:,1:],test.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIrWlqN3l9v0",
        "outputId": "49efc7dd-6b8f-4f1a-f5a2-44bf89fb9fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: xpu\n"
          ]
        }
      ],
      "source": [
        "# check for gpu (cuda means GPU is being used)\n",
        "device = torch.device('xpu' if torch.xpu.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DWiMYhB2l9v0"
      },
      "outputs": [],
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kl66Mw1rl9v0"
      },
      "outputs": [],
      "source": [
        "class myDataset(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = torch.tensor(features.values,dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels.values,dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx],self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kH_wYuvfl9v0"
      },
      "outputs": [],
      "source": [
        "train_dataset = myDataset(x_train,y_train)\n",
        "test_dataset = myDataset(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wkgrRjqjnPJV"
      },
      "outputs": [],
      "source": [
        "class myNN2(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim,num_hidden_layers,neurons_per_layer,dropout_rate):\n",
        "    super(myNN2,self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "      layers.append(nn.Linear(input_dim,neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(dropout_rate))\n",
        "      input_dim = neurons_per_layer\n",
        "    layers.append(nn.Linear(neurons_per_layer,output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, features):\n",
        "    return self.model(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "COOB5RadluDQ"
      },
      "outputs": [],
      "source": [
        "# objective fn\n",
        "def objective(trial):\n",
        "  # next hyperparameter value from search space\n",
        "  num_hidden_layers = trial.suggest_int(\"num_hidden_layers\",1,5)\n",
        "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\",8,128)\n",
        "  epochs = trial.suggest_int(\"epochs\",10,50,step=10)\n",
        "  lr = trial.suggest_float(\"lr\",1e-5,1e-1,log=True)\n",
        "  dropout_rate = trial.suggest_float(\"dropout_rate\",0.1,0.5,step=0.1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\",[16,32,64,128])\n",
        "  optimizer_name = trial.suggest_categorical(\"optm_name\",[\"Adam\",\"SGD\",\"RMSprop\"])\n",
        "  weight_decay = trial.suggest_float(\"weight_decay\",1e-5,1e-3,log=True)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset,batch_size,shuffle=False)\n",
        "\n",
        "  # model init\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "  model = myNN2(input_dim,output_dim,num_hidden_layers,neurons_per_layer,dropout_rate).to(device)\n",
        "\n",
        "  # optimizer selection / loss fn\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  if optimizer_name == \"Adam\":\n",
        "    optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "  elif optimizer_name == \"SGD\":\n",
        "    optimizer = optim.SGD(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "  else:\n",
        "    optimizer = optim.RMSprop(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "  # training loop\n",
        "  for i in range(epochs):\n",
        "    for batch_features,batch_labels in train_loader:\n",
        "      # MOVE THE FEATURES AND LABELS TO GPU\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_labels.to(device)\n",
        "\n",
        "      output = model(batch_features)\n",
        "      loss = loss_fn(output,batch_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  # evaluation\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_labels = batch_labels.to(device)\n",
        "      output = model(batch_features)\n",
        "      _,pred_val = torch.max(output,1)\n",
        "      total += batch_labels.size(0)\n",
        "      correct = correct + (pred_val==batch_labels).sum().item()\n",
        "    accuracy = 100*(correct/total)\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UorFKfRIlt-k",
        "outputId": "19adae95-bcb1-4f23-ca82-656bd70b7e7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-15 17:03:18,963] A new study created in memory with name: no-name-53016bc7-272c-4427-bcff-dd0273b8a90e\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction='maximize') # since we want to maximize accuracy, if it was loss then -> minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsDT74kRlt8K",
        "outputId": "bdfcaeec-45d3-43d9-bfbb-2072d61e7176"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-15 17:04:40,514] Trial 0 finished with value: 67.86 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 35, 'epochs': 10, 'lr': 0.033028714373505644, 'dropout_rate': 0.5, 'batch_size': 128, 'optm_name': 'SGD', 'weight_decay': 0.0005581871632277313}. Best is trial 0 with value: 67.86.\n",
            "[I 2025-06-15 17:10:26,751] Trial 1 finished with value: 84.77 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 124, 'epochs': 20, 'lr': 0.014905436619959309, 'dropout_rate': 0.2, 'batch_size': 32, 'optm_name': 'Adam', 'weight_decay': 2.2939229874591887e-05}. Best is trial 1 with value: 84.77.\n",
            "[I 2025-06-15 17:13:04,211] Trial 2 finished with value: 89.24 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 93, 'epochs': 30, 'lr': 0.08456464013916717, 'dropout_rate': 0.1, 'batch_size': 64, 'optm_name': 'SGD', 'weight_decay': 7.103375510688252e-05}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:21:27,184] Trial 3 finished with value: 80.67 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 63, 'epochs': 30, 'lr': 0.009305893993788448, 'dropout_rate': 0.5, 'batch_size': 16, 'optm_name': 'Adam', 'weight_decay': 0.00028778021231786095}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:23:35,490] Trial 4 finished with value: 87.97 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 86, 'epochs': 20, 'lr': 0.00015168890979148458, 'dropout_rate': 0.30000000000000004, 'batch_size': 32, 'optm_name': 'Adam', 'weight_decay': 0.0009378820194137556}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:31:40,453] Trial 5 finished with value: 87.18 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 98, 'epochs': 40, 'lr': 0.00033147684887444533, 'dropout_rate': 0.5, 'batch_size': 32, 'optm_name': 'RMSprop', 'weight_decay': 0.00015896816066757254}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:41:21,755] Trial 6 finished with value: 71.58 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 90, 'epochs': 50, 'lr': 3.9934278854581754e-05, 'dropout_rate': 0.30000000000000004, 'batch_size': 32, 'optm_name': 'SGD', 'weight_decay': 0.0009004803025252685}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:45:44,953] Trial 7 finished with value: 87.82 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 57, 'epochs': 50, 'lr': 2.2882133575564186e-05, 'dropout_rate': 0.2, 'batch_size': 64, 'optm_name': 'Adam', 'weight_decay': 2.4138918031241597e-05}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:47:33,321] Trial 8 finished with value: 85.78 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 31, 'epochs': 10, 'lr': 0.0014507839610756392, 'dropout_rate': 0.2, 'batch_size': 32, 'optm_name': 'RMSprop', 'weight_decay': 0.0002590899064426952}. Best is trial 2 with value: 89.24.\n",
            "[I 2025-06-15 17:48:16,798] Trial 9 finished with value: 83.62 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 56, 'epochs': 20, 'lr': 0.017166860796080593, 'dropout_rate': 0.30000000000000004, 'batch_size': 128, 'optm_name': 'Adam', 'weight_decay': 0.00015796130376552624}. Best is trial 2 with value: 89.24.\n"
          ]
        }
      ],
      "source": [
        "study.optimize(objective,n_trials=10)  # fn name , no of trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QWv2Kj8DfxPO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89.24"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z9kd_92BfxRn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num_hidden_layers': 2,\n",
              " 'neurons_per_layer': 93,\n",
              " 'epochs': 30,\n",
              " 'lr': 0.08456464013916717,\n",
              " 'dropout_rate': 0.1,\n",
              " 'batch_size': 64,\n",
              " 'optm_name': 'SGD',\n",
              " 'weight_decay': 7.103375510688252e-05}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNN8j7lFfxVD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_intel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
